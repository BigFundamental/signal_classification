{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from feature_extractor import FeatureExtractor\n",
    "from classifier import Classifier\n",
    "from signal_manager import SignalMgr\n",
    "from filter import Filter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "feaExtractor = FeatureExtractor()\n",
    "# classifier = Classifier()\n",
    "sigMgr = SignalMgr()\n",
    "\n",
    "# norm_signal = sigMgr.normalize_signals(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_signal_list(root_path, file_name = 'Channel_1.csv'):\n",
    "    test_suites = os.listdir(root_path)\n",
    "    test_cases_path = []\n",
    "    expect_result = []\n",
    "    for test in test_suites:\n",
    "        dir_path = os.path.join(root_path, test)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            continue\n",
    "        case_path = os.path.join(dir_path, file_name)\n",
    "        if not os.path.isfile(case_path):\n",
    "            continue\n",
    "        test_cases_path.append(case_path)\n",
    "        with open(case_path, 'r') as fhandler:\n",
    "            ret = fhandler.readline().strip().split(',')[0]\n",
    "            if int(ret) > 0:\n",
    "                ret = 1\n",
    "            else:\n",
    "                ret = 0\n",
    "            expect_result.append(ret)\n",
    "    return (test_cases_path, expect_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "## start evaluation of data\n",
    "# TEST_LABEL = '/Users/changkong/ML/Signal Classification/testData/20180204/labels.csv'\n",
    "RESULT_FPATH = '/Users/changkong/ML/Signal Classification/3_Application/label.csv'\n",
    "# get all data from \n",
    "TEST_DATA_ROOT = \"/Users/changkong/ML/Signal Classification/3_Application/Data/\"\n",
    "\n",
    "pathes, ret = get_signal_list(TEST_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(RESULT_FPATH, header=None, skiprows=1, names=['case_name', 'expect_result'], dtype={'expect_result':np.int32}).dropna()\n",
    "# get features\n",
    "label_df.loc[label_df.expect_result <= 1,'expect_result'] = 0\n",
    "label_df.loc[label_df.expect_result > 1, 'expect_result']= 1\n",
    "test_cases_df = pd.DataFrame(pathes, columns= ['case_path'])\n",
    "test_cases_df['case_name'] = test_cases_df['case_path'].apply(lambda x: x.split('/')[-2])\n",
    "test_cases_df['expect_result'] = ret\n",
    "test_labels = test_cases_df.merge(label_df, on='case_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÔºÅcollect new training datas\n",
    "from data_reader import DataReader\n",
    "\n",
    "dreader = DataReader()\n",
    "TEST_DATA_ROOT = '/Users/changkong/ML/Signal Classification/testData'\n",
    "label_files = dreader.search_label_files(TEST_DATA_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(result_path_list):\n",
    "    df_ret = pd.DataFrame(columns=['case_name', 'expect_result', 'reason', 'channel_id'])\n",
    "    for result_path in result_path_list:\n",
    "        df_part = create_single_index(result_path)\n",
    "        df_ret = df_ret.append(df_part)\n",
    "        print result_path, len(df_part.index), len(df_ret.index)\n",
    "    return df_ret\n",
    "\n",
    "def reason_converter(x):\n",
    "    if x == '--' or x == '':\n",
    "        return -1\n",
    "    else:\n",
    "        return int(x)\n",
    "\n",
    "def create_single_index(result_path):\n",
    "    \"\"\"\n",
    "    read csv files and create dataframe for this result.csv\n",
    "    \"\"\"\n",
    "    case_root = os.path.dirname(result_path)\n",
    "    pathes, ret = get_signal_list(case_root)\n",
    "    case_info_df = pd.DataFrame(pathes, columns = ['case_path'])\n",
    "    case_info_df['case_name'] = case_info_df['case_path'].apply(lambda x: x.split('/')[-2])\n",
    "    case_info_df['sys_result'] = map(int, ret)\n",
    "    # merge scaned info into result.csv\n",
    "    result_df = pd.read_csv(result_path, header = None, skiprows=1, names = ['case_name', 'sys_result', 'expect_result', 'reason'], usecols=[0, 2, 3], dtype={'expect_result':np.int32}, converters={'reason':reason_converter})\n",
    "    case_info_df = case_info_df.merge(result_df, on=['case_name'], how='inner')\n",
    "    return case_info_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_path='/Users/changkong/ML/Signal Classification/testData/Data.20180425/result.csv'\n",
    "# pd.read_csv(result_path, header = None, skiprows=1, names = ['case_name', 'sys_result', 'expect_result', 'reason'], usecols=[0, 2, 3], dtype={'expect_result':np.int32}, converters={'reason':reason_converter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/changkong/ML/Signal Classification/testData/Data.20180507/result.csv\n",
      "         case_name  channel_id  \\\n",
      "0  20180507_144442           1   \n",
      "1  20180507_144509           1   \n",
      "2  20180507_144556           1   \n",
      "3  20180507_144720           1   \n",
      "4  20180507_144745           1   \n",
      "\n",
      "                                           case_path  sys_result  \n",
      "0  /Users/changkong/ML/Signal Classification/test...           1  \n",
      "1  /Users/changkong/ML/Signal Classification/test...           0  \n",
      "2  /Users/changkong/ML/Signal Classification/test...           0  \n",
      "3  /Users/changkong/ML/Signal Classification/test...           0  \n",
      "4  /Users/changkong/ML/Signal Classification/test...           1  \n",
      "/Users/changkong/ML/Signal Classification/testData/Data.20180507/result.csv 7 7\n"
     ]
    }
   ],
   "source": [
    "# df_full = dreader.create_index(label_files)\n",
    "df_full = dreader.create_index(['/Users/changkong/ML/Signal Classification/testData/Data.20180507/result.csv'])\n",
    "# print label_files[23]\n",
    "# create_single_index(label_files[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['expect_result'] = map(int,(~(df_full['reason'] == -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_name</th>\n",
       "      <th>case_path</th>\n",
       "      <th>channel_id</th>\n",
       "      <th>expect_result</th>\n",
       "      <th>reason</th>\n",
       "      <th>sys_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180507_144442</td>\n",
       "      <td>/Users/changkong/ML/Signal Classification/test...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180507_144509</td>\n",
       "      <td>/Users/changkong/ML/Signal Classification/test...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180507_144556</td>\n",
       "      <td>/Users/changkong/ML/Signal Classification/test...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20180507_151116</td>\n",
       "      <td>/Users/changkong/ML/Signal Classification/test...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20180507_151139</td>\n",
       "      <td>/Users/changkong/ML/Signal Classification/test...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         case_name                                          case_path  \\\n",
       "0  20180507_144442  /Users/changkong/ML/Signal Classification/test...   \n",
       "1  20180507_144509  /Users/changkong/ML/Signal Classification/test...   \n",
       "2  20180507_144556  /Users/changkong/ML/Signal Classification/test...   \n",
       "3  20180507_151116  /Users/changkong/ML/Signal Classification/test...   \n",
       "4  20180507_151139  /Users/changkong/ML/Signal Classification/test...   \n",
       "\n",
       "  channel_id  expect_result reason  sys_result  \n",
       "0          1              1      5         1.0  \n",
       "1          1              1      5         0.0  \n",
       "2          1              1      5         0.0  \n",
       "3          1              1      5         0.0  \n",
       "4          1              1      5         0.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['reason'].value_counts()\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_path</th>\n",
       "      <th>case_name</th>\n",
       "      <th>expect_result_x</th>\n",
       "      <th>expect_result_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Users/changkong/ML/Signal Classification/3_Ap...</td>\n",
       "      <td>20180325_090536</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Users/changkong/ML/Signal Classification/3_Ap...</td>\n",
       "      <td>20180325_090637</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Users/changkong/ML/Signal Classification/3_Ap...</td>\n",
       "      <td>20180325_091016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Users/changkong/ML/Signal Classification/3_Ap...</td>\n",
       "      <td>20180325_091047</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Users/changkong/ML/Signal Classification/3_Ap...</td>\n",
       "      <td>20180325_091103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           case_path        case_name  \\\n",
       "0  /Users/changkong/ML/Signal Classification/3_Ap...  20180325_090536   \n",
       "1  /Users/changkong/ML/Signal Classification/3_Ap...  20180325_090637   \n",
       "2  /Users/changkong/ML/Signal Classification/3_Ap...  20180325_091016   \n",
       "3  /Users/changkong/ML/Signal Classification/3_Ap...  20180325_091047   \n",
       "4  /Users/changkong/ML/Signal Classification/3_Ap...  20180325_091103   \n",
       "\n",
       "   expect_result_x  expect_result_y  \n",
       "0                1                0  \n",
       "1                0                1  \n",
       "2                0                0  \n",
       "3                0                0  \n",
       "4                0                0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels['expect_result'] = test_labels['expect_result_x']\n",
    "test_labels = test_labels.drop(['expect_result_x', 'expect_result_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full = df_full.drop(['reason', 'sys_result'], axis=1).append(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7\n",
       "Name: expect_result, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['expect_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_df = pd.DataFrame()\n",
    "pathes = df_full['case_path']\n",
    "# print pathes\n",
    "feature_set = dict()\n",
    "feature_set['peaks_num'] = list()\n",
    "feature_set['down_peaks_num'] = list()\n",
    "feature_set['up_edges_num'] = list()\n",
    "feature_set['down_edges_num'] = list()\n",
    "feature_set['peak_edge_ratio'] = list()\n",
    "feature_set['down_peak_edge_ratio'] = list()\n",
    "feature_set['edge_diff_10'] = list()\n",
    "feature_set['edge_diff_20'] = list()\n",
    "# feature_set['edge_diff_30'] = list()\n",
    "feature_set['edge_diff_50'] = list()\n",
    "feature_set['width_diff_10'] = list()\n",
    "# feature_set['width_diff_20'] = list()\n",
    "# feature_set['width_diff_30'] = list()\n",
    "# feature_set['width_diff_50'] = list()\n",
    "row_num = 0\n",
    "for test_case in pathes:\n",
    "#     print row_num\n",
    "    features = sigMgr.get_features(test_case, request_param={'skip_row':[1], 'model_path':'train'})\n",
    "    feature_set['peaks_num'].append(features['peaks_num'])\n",
    "    feature_set['up_edges_num'].append(features['up_edges_num'])\n",
    "    feature_set['down_edges_num'].append(features['down_edges_num'])\n",
    "    feature_set['down_peaks_num'].append(features['down_peaks_num'])\n",
    "    feature_set['peak_edge_ratio'].append(features['peak_edge_ratio'])\n",
    "    feature_set['down_peak_edge_ratio'].append(features['down_peak_edge_ratio'])\n",
    "    feature_set['edge_diff_10'].append(features['edge_diff_10'])\n",
    "    feature_set['edge_diff_20'].append(features['edge_diff_20'])\n",
    "#     feature_set['edge_diff_30'].append(features['edge_diff_30'])\n",
    "    feature_set['edge_diff_50'].append(features['edge_diff_50'])\n",
    "    feature_set['width_diff_10'].append(features['width_diff_10'])\n",
    "    row_num += 1\n",
    "#     feature_set['width_diff_20'].append(features['width_diff_20'])\n",
    "#     feature_set['width_diff_30'].append(features['width_diff_30'])\n",
    "#     feature_set['width_diff_50'].append(features['width_diff_50'])\n",
    "#     break\n",
    "\n",
    "dataset = pd.DataFrame(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['label'] = df_full['expect_result'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>down_edges_num</th>\n",
       "      <th>down_peak_edge_ratio</th>\n",
       "      <th>down_peaks_num</th>\n",
       "      <th>edge_diff_10</th>\n",
       "      <th>edge_diff_20</th>\n",
       "      <th>edge_diff_50</th>\n",
       "      <th>peak_edge_ratio</th>\n",
       "      <th>peaks_num</th>\n",
       "      <th>up_edges_num</th>\n",
       "      <th>width_diff_10</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>40</td>\n",
       "      <td>0.159664</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.063158</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>38</td>\n",
       "      <td>0.259514</td>\n",
       "      <td>0.172742</td>\n",
       "      <td>0.055804</td>\n",
       "      <td>1.164557</td>\n",
       "      <td>46</td>\n",
       "      <td>40</td>\n",
       "      <td>1.315000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0.853659</td>\n",
       "      <td>35</td>\n",
       "      <td>0.108172</td>\n",
       "      <td>0.081966</td>\n",
       "      <td>0.061442</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>30</td>\n",
       "      <td>41</td>\n",
       "      <td>1.011111</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>36</td>\n",
       "      <td>0.211523</td>\n",
       "      <td>0.158777</td>\n",
       "      <td>0.075151</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>31</td>\n",
       "      <td>40</td>\n",
       "      <td>0.639394</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>27</td>\n",
       "      <td>0.080412</td>\n",
       "      <td>0.068893</td>\n",
       "      <td>0.040169</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>26</td>\n",
       "      <td>42</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   down_edges_num  down_peak_edge_ratio  down_peaks_num  edge_diff_10  \\\n",
       "0              41              0.975610              40      0.159664   \n",
       "1              39              0.962025              38      0.259514   \n",
       "2              41              0.853659              35      0.108172   \n",
       "3              41              0.888889              36      0.211523   \n",
       "4              42              0.642857              27      0.080412   \n",
       "\n",
       "   edge_diff_20  edge_diff_50  peak_edge_ratio  peaks_num  up_edges_num  \\\n",
       "0      0.116667      0.063158         0.756098         31            41   \n",
       "1      0.172742      0.055804         1.164557         46            40   \n",
       "2      0.081966      0.061442         0.731707         30            41   \n",
       "3      0.158777      0.075151         0.765432         31            40   \n",
       "4      0.068893      0.040169         0.619048         26            42   \n",
       "\n",
       "   width_diff_10  label  \n",
       "0       1.111111      1  \n",
       "1       1.315000      1  \n",
       "2       1.011111      1  \n",
       "3       0.639394      1  \n",
       "4       0.583333      1  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "msk = np.random.rand(len(dataset)) < 0.8\n",
    "label = dataset['label']\n",
    "\n",
    "# x = dataset.drop('label', axis=1)\n",
    "# train_x = x[msk].reset_index(drop=True)\n",
    "# test_x = x[~msk].reset_index(drop=True)\n",
    "# train_y = label[msk].reset_index(drop=True)\n",
    "# test_y = label[~msk].reset_index(drop=True)\n",
    "x = dataset.drop('label', axis=1)\n",
    "train_x = x[msk]\n",
    "test_x = x[~msk]\n",
    "train_y = label[msk]\n",
    "test_y = label[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.59      0.72      0.65      1359\n",
      "          1       0.75      0.63      0.68      1823\n",
      "\n",
      "avg / total       0.68      0.67      0.67      3182\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier as ada\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# train_new_x = train_x.drop(['width_diff_20', 'width_diff_30', 'edge_diff_30'], axis=1)\n",
    "# test_new_x = test_x.drop(['width_diff_20', 'width_diff_30','edge_diff_30'], axis=1)\n",
    "train_new_x = train_x\n",
    "test_new_x = test_x\n",
    "adaModel = ada(n_estimators=100, learning_rate = 0.7, random_state=10)\n",
    "adaModel.fit(train_new_x, train_y)\n",
    "pResult = adaModel.predict(test_new_x)\n",
    "# possiblities = adaModel.predict_proba(test_x)\n",
    "# pResult = [int(p0 < p1 + 0.011) for p0, p1 in possiblities]\n",
    "# pResult = possiblities.where(possiblities >= 0.6, 1, 0)\n",
    "print(classification_report(test_y, pResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
