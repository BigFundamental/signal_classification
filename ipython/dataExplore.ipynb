{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from feature_extractor import FeatureExtractor\n",
    "from classifier import Classifier\n",
    "from signal_manager import SignalMgr\n",
    "from filter import Filter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "feaExtractor = FeatureExtractor()\n",
    "# classifier = Classifier()\n",
    "sigMgr = SignalMgr()\n",
    "\n",
    "# norm_signal = sigMgr.normalize_signals(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_signal_list(root_path, file_name = 'Channel_1.csv'):\n",
    "    test_suites = os.listdir(root_path)\n",
    "    test_cases_path = []\n",
    "    expect_result = []\n",
    "    for test in test_suites:\n",
    "        dir_path = os.path.join(root_path, test)\n",
    "        if not os.path.isdir(dir_path):\n",
    "            continue\n",
    "        case_path = os.path.join(dir_path, file_name)\n",
    "        if not os.path.isfile(case_path):\n",
    "            continue\n",
    "        test_cases_path.append(case_path)\n",
    "        with open(case_path, 'r') as fhandler:\n",
    "            ret = fhandler.readline().strip().split(',')[0]\n",
    "            if int(ret) > 0:\n",
    "                ret = 1\n",
    "            else:\n",
    "                ret = 0\n",
    "            expect_result.append(ret)\n",
    "    return (test_cases_path, expect_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#！collect new training datas\n",
    "from data_reader import DataReader\n",
    "\n",
    "dreader = DataReader()\n",
    "# TEST_DATA_ROOT = '/Users/changkong/ML/Signal Classification/testData'\n",
    "TEST_DATA_ROOT = '/Users/changkong/ML/Signal Classification/testData/1005_0830重新标注文件_Data._20180609.0830'\n",
    "TEST_DATA_ROOT1 = '/Users/changkong/ML/Signal Classification/testData/0830_1005_goods_Data.20180611'\n",
    "# TEST_DATA_ROOT='/Users/changkong/ML/Signal Classification/testData/1005_Data20180609/'\n",
    "label_files1 = dreader.search_label_files(TEST_DATA_ROOT)\n",
    "label_goods = dreader.search_label_files(TEST_DATA_ROOT1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/changkong/ML/Signal Classification/testData/0830_1005_goods_Data.20180611/result.csv']\n"
     ]
    }
   ],
   "source": [
    "# print label_files\n",
    "print label_goods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_files = [label_files1[0], label_goods[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/changkong/ML/Signal Classification/testData/0830_1005_goods_Data.20180611/result.csv 2903 2903\n"
     ]
    }
   ],
   "source": [
    "df_tmp = dreader.create_index([label_goods[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2    1907\n",
       "-1     672\n",
       " 0     163\n",
       " 5      90\n",
       " 3      35\n",
       " 7      16\n",
       " 1      15\n",
       " 4       4\n",
       " 2       1\n",
       "Name: reason, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tmp['reason'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class1_goods = df_tmp[(df_tmp.reason == -1) | (df_tmp.reason == -2)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/changkong/ML/Signal Classification/testData/1005_0830重新标注文件_Data._20180609.0830/result.csv 7545 7545\n"
     ]
    }
   ],
   "source": [
    "df_relabel = dreader.create_index([label_files1[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full = df_class1_goods.append(df_relabel).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class1_goods['expect_result'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = df_relabel.append(df_class1_goods).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5470\n",
       "1    4654\n",
       "Name: expect_result, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['expect_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4654\n",
       "0    2891\n",
       "Name: expect_result, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_relabel['expect_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_df = pd.DataFrame()\n",
    "pathes = df_full['case_path']\n",
    "# print pathes\n",
    "feature_set = dict()\n",
    "feature_set['peaks_num'] = list()\n",
    "feature_set['down_peaks_num'] = list()\n",
    "feature_set['up_edges_num'] = list()\n",
    "feature_set['down_edges_num'] = list()\n",
    "feature_set['peak_edge_ratio'] = list()\n",
    "feature_set['down_peak_edge_ratio'] = list()\n",
    "feature_set['edge_diff_10'] = list()\n",
    "feature_set['edge_diff_20'] = list()\n",
    "# feature_set['edge_diff_30'] = list()\n",
    "# feature_set['edge_diff_50'] = list()\n",
    "feature_set['width_diff_10'] = list()\n",
    "feature_set['negative_peak_num'] = list()\n",
    "feature_set['max_down_peak_point'] = list()\n",
    "# feature_set['width_diff_20'] = list()\n",
    "# feature_set['width_diff_30'] = list()\n",
    "# feature_set['width_diff_50'] = list()\n",
    "row_num = 0\n",
    "for test_case in pathes:\n",
    "#     print row_num\n",
    "    features = sigMgr.get_features(test_case, request_param={'skip_row':[1], 'model_path':['train']})\n",
    "    feature_set['peaks_num'].append(features['peaks_num'])\n",
    "    feature_set['up_edges_num'].append(features['up_edges_num'])\n",
    "    feature_set['down_edges_num'].append(features['down_edges_num'])\n",
    "    feature_set['down_peaks_num'].append(features['down_peaks_num'])\n",
    "    feature_set['peak_edge_ratio'].append(features['peak_edge_ratio'])\n",
    "    feature_set['down_peak_edge_ratio'].append(features['down_peak_edge_ratio'])\n",
    "    feature_set['edge_diff_10'].append(features['edge_diff_10'])\n",
    "    feature_set['edge_diff_20'].append(features['edge_diff_20'])\n",
    "#     feature_set['edge_diff_30'].append(features['edge_diff_30'])\n",
    "#     feature_set['edge_diff_50'].append(features['edge_diff_50'])\n",
    "    feature_set['width_diff_10'].append(features['width_diff_10'])\n",
    "    feature_set['negative_peak_num'].append(features['negative_peak_num'])\n",
    "    feature_set['max_down_peak_point'].append(features['max_down_peak_point'])\n",
    "    row_num += 1\n",
    "#     feature_set['width_diff_20'].append(features['width_diff_20'])\n",
    "#     feature_set['width_diff_30'].append(features['width_diff_30'])\n",
    "#     feature_set['width_diff_50'].append(features['width_diff_50'])\n",
    "#     break\n",
    "\n",
    "dataset = pd.DataFrame(feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['label'] = df_full['expect_result'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()\n",
    "dataset_backup = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "msk = np.random.rand(len(dataset)) < 0.8\n",
    "label = dataset['label']\n",
    "\n",
    "# x = dataset.drop('label', axis=1)\n",
    "# train_x = x[msk].reset_index(drop=True)\n",
    "# test_x = x[~msk].reset_index(drop=True)\n",
    "# train_y = label[msk].reset_index(drop=True)\n",
    "# test_y = label[~msk].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop(['label'], axis=1)\n",
    "train_x = x[msk]\n",
    "test_x = x[~msk]\n",
    "train_y = label[msk]\n",
    "test_y = label[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x_neg = dataset[msk & (dataset.label == 1)].sample(n = 1000)\n",
    "# train_x_pos = dataset[msk & (dataset.label == 0)].sample(n = 2000)\n",
    "# train_x = train_x.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95      1083\n",
      "          1       0.95      0.92      0.93       901\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier as ada\n",
    "from sklearn.linear_model import LogisticRegression as lg\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# train_new_x = train_x.drop(['width_diff_20', 'width_diff_30', 'edge_diff_30'], axis=1)\n",
    "# test_new_x = test_x.drop(['width_diff_20', 'width_diff_30','edge_diff_30'], axis=1)\n",
    "train_new_x = train_x\n",
    "test_new_x = test_x\n",
    "adaModel = ada(n_estimators=200, learning_rate = 0.5, random_state=10)\n",
    "adaModel.fit(train_new_x, train_y)\n",
    "pResult = adaModel.predict(test_new_x)\n",
    "# possiblities = adaModel.predict_proba(test_x)\n",
    "# pResult = [int(p0 < p1 + 0.011) for p0, p1 in possiblities]\n",
    "# pResult = possiblities.where(possiblities >= 0.6, 1, 0)\n",
    "print(classification_report(test_y, pResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.95      0.95      1083\n",
      "          1       0.94      0.93      0.94       901\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1984\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gdbtModel = GradientBoostingClassifier()\n",
    "gdbtModel.fit(train_x, train_y)\n",
    "pResult = gdbtModel.predict(test_x)\n",
    "print(classification_report(test_y, pResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../model/model.pkl']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(gdbtModel, '../model/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.96      0.95      5470\n",
      "          1       0.95      0.93      0.94      4654\n",
      "\n",
      "avg / total       0.94      0.94      0.94     10124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = dataset['label']\n",
    "features = dataset.drop('label', axis=1)\n",
    "pResult = gdbtModel.predict(features)\n",
    "print(classification_report(label, pResult))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = label == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pResult == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predit_positvie = pResult == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[predit_positvie].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[predit_positvie].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label[predit_positvie].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "42.0 / 205.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
